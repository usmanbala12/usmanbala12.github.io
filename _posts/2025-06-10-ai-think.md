---
layout: post
title: "The point is not whether AI can 'think' or not"
date: 2025-06-10
categories: blog
twitter_image: "/assets/twitter.jpeg"
---

Recently, Apple released a paper (👉[link](https://machinelearning.apple.com/research/illusion-of-thinking)) investigating the illusion and limitation of "thinking" in current AI models — a claim that quickly rippled through the machine learning community. As usual, reactions differed. Some saw it as vindication for long-held beliefs; others dismissed it as inconclusive or ill-defined. But to me, the entire debate seems to miss the real point.
When asked whether computers could think, Edsger Dijkstra famously replied, *“The question of whether a computer can think is no more interesting than the question of whether a submarine can swim.”* This elegantly encapsulates the core insight I want to share.

Human innovation has always been inspired by nature. Often, it goes beyond inspiration to outright mimicry. But have we ever replicated nature perfectly? Not once. And that’s precisely the point.

Take airplanes for example. They operate under the same physical laws as birds. Yet, they are a far cry from the elegance of avian flight. Airplanes are massive, metallic, and reliant on an imperfect infrastructure. Birds are small, agile, self-healing, and require no human intervention. However, planes can carry hundreds of people across continents in hours, something no bird could do. In trying to mimic nature, we didn’t replicate it but rather created something uniquely powerful in its own right. The same applies to submarines. No, they don't swim like fish. But they enable deep-sea exploration, global logistics, and defense strategies that were never conceived before.

This analogy extends naturally to AI. In trying to emulate intelligence, we borrowed from biology; neural networks, synapses, feedback loops but then we diverged. Fueled by massive data and unprecedented compute, we’ve built systems that don’t think like us, but can still do things we can’t.

AI can’t "reason" like humans, at least not yet, and maybe never. But it can ingest and analyze terabytes of data faster than any person. It can detect cancerous cells in radiology scans, generate photorealistic images, simulate protein folding, and help land rockets with sub-meter precision. That’s not artificial human reasoning but it is intelligence of a different kind. And that’s valuable.

Yes, AI lacks our emotional nuance, lived experience, and ethical intuition. It can’t infuse sentences with personality. And that’s okay.
The real question isn’t whether AI thinks or reasons. The real questions are:

- *What can it do that we can’t?*
- *What strengths does it have that we can amplify?*
- *And how can we design systems that best harness those differences?*

This is how progress has always worked. We didn’t make birds. We made planes. We didn’t make fish. We made submarines. And with AI, we won’t recreate the human mind but we’ll build something that expands what minds can do. Let’s stop asking whether AI is like us and start asking what it can do for us. By leveraging its strengths alongside ours, we might create a future richer than anything either biology or code could achieve alone.
